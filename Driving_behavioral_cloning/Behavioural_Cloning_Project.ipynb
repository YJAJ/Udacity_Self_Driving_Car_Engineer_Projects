{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavioral Cloning Project with Darknet53"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from skimage.transform import rotate\n",
    "from skimage.filters import gaussian\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Conv2D, Activation, BatchNormalization, Dense, \\\n",
    "LeakyReLU, GlobalAveragePooling2D, Dropout, Flatten, Lambda, add\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.initializers import he_normal\n",
    "from keras.regularizers import l2\n",
    "from typing import Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will prepare DataLoader class to load and augment the data and split it into train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, path, sz):\n",
    "        self.path = path\n",
    "        self.df = self.load_data(\"driving_log.csv\")\n",
    "        self.new_df = self.load_data(\"extended_log.csv\")\n",
    "        self.h, self.w, self.ch = sz\n",
    "        \n",
    "    def load_data(self, file_name):\n",
    "        path_to_csv = os.path.join(self.path, file_name)\n",
    "        df = pd.read_csv(path_to_csv)\n",
    "        return df\n",
    "        \n",
    "    def load_image(self, file_name):\n",
    "        path_to_image = os.path.join(self.path, file_name)\n",
    "        image = cv2.imread(path_to_image)\n",
    "        return image\n",
    "\n",
    "    def match_X_y(self):\n",
    "        new_df = pd.DataFrame(columns=['image', 'steering_angle'])\n",
    "        new_df['image'] = None\n",
    "        new_df['steering_angle'] = 0.\n",
    "        cols = ['center', 'left', 'right']\n",
    "        k = 0\n",
    "        for col in cols:\n",
    "            for i in range(len(self.df)):\n",
    "                new_df.at[i+k, 'image'] = self.df.at[i, col]\n",
    "                if col=='center':\n",
    "                    new_df.at[i+k, 'steering_angle'] = self.df.at[i, 'steering']\n",
    "                elif col=='left':\n",
    "                    new_df.at[i+k, 'steering_angle'] = self.df.at[i, 'steering'] + 0.2\n",
    "                else:\n",
    "                    new_df.at[i+k, 'steering_angle'] = self.df.at[i, 'steering'] - 0.2\n",
    "            k += len(self.df)\n",
    "        new_df.to_csv(os.path.join(self.path, \"extended_log.csv\"))          \n",
    "        \n",
    "    def flip_horizontal(self, X_i):\n",
    "        image = X_i[:, ::-1]\n",
    "        return image\n",
    "    \n",
    "    #reference from https://subscription.packtpub.com/book/application_development/9781785283932/1/ch01lvl1sec11/image-translation\n",
    "    def shift(self, X_i, y_i):\n",
    "        w = X_i.shape[1]\n",
    "        h = X_i.shape[0]\n",
    "        #shift range between -0.10 and 0.10\n",
    "        shift_w = w * (random.random()*0.2-0.1)\n",
    "        shift_h = h * (random.random()*0.2-0.1)\n",
    "        #adjust steering angle slightly\n",
    "        s_angle = y_i + shift_w*1e-04\n",
    "        #M = 2x3 transformation matrix\n",
    "        M = np.float32([[1, 0, shift_w],[0, 1, shift_h]])\n",
    "        #https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html?highlight=getrotationmatrix2d\n",
    "        image = cv2.warpAffine(X_i, M, (w, h))\n",
    "        return image, s_angle\n",
    "    \n",
    "    def blur(self, X_i):\n",
    "        random_int = random.randrange(4)\n",
    "        image = gaussian(X_i, random_int, multichannel=True, mode='reflect')\n",
    "        return image\n",
    "    \n",
    "    #reference from https://stackoverflow.com/questions/32609098/how-to-fast-change-image-brightness-with-python-opencv\n",
    "    def adjust_brightness(self, X_i):\n",
    "        #change to hsv\n",
    "        img_hsv = cv2.cvtColor(X_i, cv2.COLOR_RGB2HSV)\n",
    "        #brigthness, third channel - value range is [0,255], can be darker or brighter by degree between -0.5 and 0.5\n",
    "        brightness = img_hsv[:,:,2]*(random.random()-0.5)\n",
    "        img_hsv[:,:,2] += brightness.astype(np.uint8)\n",
    "        return cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    def augment_data(self, X, y):\n",
    "        if len(X)!=0:\n",
    "            X_augmented = []\n",
    "            y_augmented = []\n",
    "            for i in range(len(X)):      \n",
    "                X_i = self.load_image(X[i].strip())\n",
    "                X_copy = copy.deepcopy(X_i)\n",
    "\n",
    "                #original image\n",
    "                X_copy = self.flip_horizontal(X_copy)\n",
    "                X_augmented.append(self.crop_sky_car(X_i))\n",
    "                y_augmented.append(y[i])\n",
    "                #flipped image with adjusted y steering angle\n",
    "                X_augmented.append(self.crop_sky_car(X_copy))\n",
    "                y_augmented.append(-y[i])\n",
    "                #other augmentations with probility\n",
    "                X_copy = copy.deepcopy(X_i)\n",
    "                y_copy = copy.deepcopy(y[i])\n",
    "                #random probability and threshold\n",
    "                rand_prob = random.random()\n",
    "                thres = 0.4\n",
    "                if rand_prob > thres:\n",
    "                    rand_transform = random.randrange(3)\n",
    "                    if rand_transform==0:\n",
    "                        X_copy, y_copy = self.shift(X_copy, y_copy)\n",
    "                    if rand_transform==1:\n",
    "                        X_copy = self.blur(X_copy)\n",
    "                    if rand_transform==2:\n",
    "                        X_copy = self.adjust_brightness(X_copy)\n",
    "                    X_augmented.append(self.crop_sky_car(X_copy))\n",
    "                    y_augmented.append(y_copy)\n",
    "        assert len(X_augmented)==len(y_augmented)\n",
    "        return X_augmented, y_augmented  \n",
    "    \n",
    "    def split_data(self):\n",
    "        #augment the dataset to increase and transform images\n",
    "        X_augmented, y_augmented = self.augment_data(self.new_df['image'], self.new_df['steering_angle'])\n",
    "        \n",
    "        #split train and valid set\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_augmented, y_augmented, test_size=0.2, \n",
    "                                                              random_state=42, shuffle=True)\n",
    "        return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to define the path to data, both images and csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data_ext/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, DataLoader is instantiated with the size of images as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader(data_path, (160, 320, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new csv to utilise three different images\n",
    "# data.match_X_y()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split_data step encompasses data augmentation in this case. \n",
    "\n",
    "There are four data augmentation methods adopted for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = data.split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80848, 20212, 80848, 20212)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_valid), len(y_train), len(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X, y, bs):\n",
    "    len_X = len(X)\n",
    "    #for generator, a continuous loop\n",
    "    while True:\n",
    "        X, y = shuffle(X, y)\n",
    "\n",
    "        #batch generator\n",
    "        for offset in range(0, len_X, bs):\n",
    "            batch_X, batch_y = X[offset:offset+bs], y[offset:offset+bs]\n",
    "            \n",
    "            images = []\n",
    "            s_angles = []\n",
    "            for i in range(len(batch_X)):\n",
    "\n",
    "                images.append(batch_X[i])\n",
    "                s_angles.append(batch_y[i])\n",
    "            X_batch = np.array(images)\n",
    "            y_batch = np.array(s_angles)\n",
    "\n",
    "            yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, I decided to use Darknet53, the backbone of YoloV3, for a steering angle prediction. \n",
    "\n",
    "Darknet53 performs well utilising Resnet layers with a relatively smaller number of billions of operations and billion floating operations per second (please see the comparison table below from [YOLOv3 paper](https://pjreddie.com/media/files/papers/YOLOv3.pdf). This is one of the reason why YoloV3 is able to produce a real-time prediction on embedded devices.\n",
    "\n",
    "I believe that an efficient operation without sacrificing performance is crucial to computer vision components supporting self driving car engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Comparsion_between_Darknet_and_Resnet](examples/darknet53.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbl(input_data, soutput:int, skernel:int=3, stride:int=1, weight_decay=5e-04):\n",
    "    x = Conv2D(soutput, (skernel, skernel), padding='same', strides=stride, kernel_regularizer=l2(weight_decay))(input_data)\n",
    "    x = BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, \n",
    "                                 beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', \n",
    "                                 moving_variance_initializer='ones')(x)\n",
    "    x = LeakyReLU(alpha=0.3)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_unit(input_data, soutput:int):\n",
    "    x = dbl(input_data, soutput//2, 1)\n",
    "    x = dbl(x, soutput, 3)\n",
    "\n",
    "    return add([input_data, x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_unit_block(input_data, soutput:int, num_block:int):\n",
    "    x = res_unit(input_data, soutput)\n",
    "    \n",
    "    for i in range(num_block-1):\n",
    "        x = res_unit(x, soutput)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I replaced the last fully connected layer, which has 1000 classes (for Imagenet dataset), and the softmax layer with only one-output fully connected layer so that the whole model can provide a single number that indicates a steering angle. Therefore, this architecture is for a regression problem, instead of a classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darknet53(sinput:Collection[int], num_blocks:Collection[int], output_sz:int=32):\n",
    "    input_shape = Input(shape=sinput)\n",
    "    x = Lambda(lambda x: x/255.0-0.5, input_shape=sinput)(input_shape)\n",
    "    \n",
    "    #dbl in 3 channels, out 32 channels\n",
    "    x = dbl(x, output_sz, 3, 1)\n",
    "\n",
    "    #first - one dbl one res units - in 32 channels, out 64 channels\n",
    "    x = dbl(x, output_sz*2, 3, 1)\n",
    "    x = res_unit_block(x, output_sz*2, num_blocks[0])\n",
    "\n",
    "    #second - one dbl two res units - in 64 ch, out 128 ch\n",
    "    x = dbl(x, output_sz*4, 3, 2)\n",
    "    x = res_unit_block(x, output_sz*4, num_blocks[1])\n",
    "\n",
    "    #third - one dbl eight res units - in 128 ch, out 256 ch\n",
    "    x = dbl(x, output_sz*8, 3, 2)\n",
    "    x = res_unit_block(x, output_sz*8, num_blocks[2])\n",
    "\n",
    "    #four - one dbl eight res units - in 256 ch, out 512 ch\n",
    "    x = dbl(x, output_sz*16, 3, 2)\n",
    "    x = res_unit_block(x, output_sz*16, num_blocks[3])\n",
    "\n",
    "    #five - one dbl four res units - in 512 ch, out 1024 ch\n",
    "    x = dbl(x, output_sz*32, 3, 2)\n",
    "    x = res_unit_block(x, output_sz*32, num_blocks[4])\n",
    "#     print(x.shape)\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "#     print(x.shape)\n",
    "#     x = Flatten()(x)\n",
    "    x = Dense(units=1)(x)\n",
    "\n",
    "    model = Model(inputs=input_shape, outputs=x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will take the input size of 160 Height, 320 Width and 3 Channel (BGR from CV2). There are five blocks that have different number of layers: 1, 2, 8, 8, 4, respectively. I will create a model with these configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Honey\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Honey\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Honey\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Honey\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Honey\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Honey\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = darknet53((160, 320, 3), [1, 2, 8, 8, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to investigate the model architecture to ensure the correct configuration. In my case, I found Lambda layer was missing, by looking at the architecture below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 160, 320, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 160, 320, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 160, 320, 32) 896         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 160, 320, 32) 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 160, 320, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 160, 320, 64) 18496       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 160, 320, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 160, 320, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 160, 320, 32) 2080        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 160, 320, 32) 128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 160, 320, 32) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 160, 320, 64) 18496       leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 160, 320, 64) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 160, 320, 64) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 160, 320, 64) 0           leaky_re_lu_2[0][0]              \n",
      "                                                                 leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 80, 160, 128) 73856       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 80, 160, 128) 512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 80, 160, 128) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 80, 160, 64)  8256        leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 80, 160, 64)  256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 80, 160, 64)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 80, 160, 128) 73856       leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 80, 160, 128) 512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 80, 160, 128) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 80, 160, 128) 0           leaky_re_lu_5[0][0]              \n",
      "                                                                 leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 80, 160, 64)  8256        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 80, 160, 64)  256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 80, 160, 64)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 80, 160, 128) 73856       leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 80, 160, 128) 512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 80, 160, 128) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 80, 160, 128) 0           add_2[0][0]                      \n",
      "                                                                 leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 40, 80, 256)  295168      add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 40, 80, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 40, 80, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 40, 80, 128)  32896       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 40, 80, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 40, 80, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 40, 80, 256)  295168      leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 40, 80, 256)  1024        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 40, 80, 256)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 40, 80, 256)  0           leaky_re_lu_10[0][0]             \n",
      "                                                                 leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 40, 80, 128)  32896       add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 40, 80, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 40, 80, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 40, 80, 256)  295168      leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 40, 80, 256)  1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 40, 80, 256)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 40, 80, 256)  0           add_4[0][0]                      \n",
      "                                                                 leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 40, 80, 128)  32896       add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 40, 80, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 40, 80, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 40, 80, 256)  295168      leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 40, 80, 256)  1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 40, 80, 256)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 40, 80, 256)  0           add_5[0][0]                      \n",
      "                                                                 leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 40, 80, 128)  32896       add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 40, 80, 128)  512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 40, 80, 128)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 40, 80, 256)  295168      leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 40, 80, 256)  1024        conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 40, 80, 256)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 40, 80, 256)  0           add_6[0][0]                      \n",
      "                                                                 leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 40, 80, 128)  32896       add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 40, 80, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 40, 80, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 40, 80, 256)  295168      leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 40, 80, 256)  1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 40, 80, 256)  0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 40, 80, 256)  0           add_7[0][0]                      \n",
      "                                                                 leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 40, 80, 128)  32896       add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 40, 80, 128)  512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)      (None, 40, 80, 128)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 40, 80, 256)  295168      leaky_re_lu_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 40, 80, 256)  1024        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)      (None, 40, 80, 256)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 40, 80, 256)  0           add_8[0][0]                      \n",
      "                                                                 leaky_re_lu_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 40, 80, 128)  32896       add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 40, 80, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)      (None, 40, 80, 128)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 40, 80, 256)  295168      leaky_re_lu_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 40, 80, 256)  1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)      (None, 40, 80, 256)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 40, 80, 256)  0           add_9[0][0]                      \n",
      "                                                                 leaky_re_lu_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 40, 80, 128)  32896       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 40, 80, 128)  512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)      (None, 40, 80, 128)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 40, 80, 256)  295168      leaky_re_lu_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 40, 80, 256)  1024        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)      (None, 40, 80, 256)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 40, 80, 256)  0           add_10[0][0]                     \n",
      "                                                                 leaky_re_lu_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 20, 40, 512)  1180160     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 20, 40, 512)  2048        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)      (None, 20, 40, 512)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 20, 40, 256)  131328      leaky_re_lu_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 20, 40, 256)  1024        conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)      (None, 20, 40, 256)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 20, 40, 512)  1180160     leaky_re_lu_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 20, 40, 512)  2048        conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)      (None, 20, 40, 512)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 20, 40, 512)  0           leaky_re_lu_27[0][0]             \n",
      "                                                                 leaky_re_lu_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 20, 40, 256)  131328      add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 20, 40, 256)  1024        conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)      (None, 20, 40, 256)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 20, 40, 512)  1180160     leaky_re_lu_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 20, 40, 512)  2048        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)      (None, 20, 40, 512)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 20, 40, 512)  0           add_12[0][0]                     \n",
      "                                                                 leaky_re_lu_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 20, 40, 256)  131328      add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 20, 40, 256)  1024        conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)      (None, 20, 40, 256)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 20, 40, 512)  1180160     leaky_re_lu_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 20, 40, 512)  2048        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)      (None, 20, 40, 512)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 20, 40, 512)  0           add_13[0][0]                     \n",
      "                                                                 leaky_re_lu_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 20, 40, 256)  131328      add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 20, 40, 256)  1024        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)      (None, 20, 40, 256)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 20, 40, 512)  1180160     leaky_re_lu_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 20, 40, 512)  2048        conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)      (None, 20, 40, 512)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 20, 40, 512)  0           add_14[0][0]                     \n",
      "                                                                 leaky_re_lu_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 20, 40, 256)  131328      add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 20, 40, 256)  1024        conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)      (None, 20, 40, 256)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 20, 40, 512)  1180160     leaky_re_lu_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 20, 40, 512)  2048        conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)      (None, 20, 40, 512)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 20, 40, 512)  0           add_15[0][0]                     \n",
      "                                                                 leaky_re_lu_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 20, 40, 256)  131328      add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 20, 40, 256)  1024        conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)      (None, 20, 40, 256)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 20, 40, 512)  1180160     leaky_re_lu_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 20, 40, 512)  2048        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)      (None, 20, 40, 512)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 20, 40, 512)  0           add_16[0][0]                     \n",
      "                                                                 leaky_re_lu_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 20, 40, 256)  131328      add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 20, 40, 256)  1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)      (None, 20, 40, 256)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 20, 40, 512)  1180160     leaky_re_lu_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 20, 40, 512)  2048        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)      (None, 20, 40, 512)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 20, 40, 512)  0           add_17[0][0]                     \n",
      "                                                                 leaky_re_lu_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 20, 40, 256)  131328      add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 20, 40, 256)  1024        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)      (None, 20, 40, 256)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 20, 40, 512)  1180160     leaky_re_lu_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 20, 40, 512)  2048        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)      (None, 20, 40, 512)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 20, 40, 512)  0           add_18[0][0]                     \n",
      "                                                                 leaky_re_lu_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 10, 20, 1024) 4719616     add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 10, 20, 1024) 4096        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)      (None, 10, 20, 1024) 0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 10, 20, 512)  524800      leaky_re_lu_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 10, 20, 512)  2048        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)      (None, 10, 20, 512)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 10, 20, 1024) 4719616     leaky_re_lu_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 10, 20, 1024) 4096        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)      (None, 10, 20, 1024) 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 10, 20, 1024) 0           leaky_re_lu_44[0][0]             \n",
      "                                                                 leaky_re_lu_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 10, 20, 512)  524800      add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 10, 20, 512)  2048        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)      (None, 10, 20, 512)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 10, 20, 1024) 4719616     leaky_re_lu_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 10, 20, 1024) 4096        conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)      (None, 10, 20, 1024) 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 10, 20, 1024) 0           add_20[0][0]                     \n",
      "                                                                 leaky_re_lu_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 10, 20, 512)  524800      add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 10, 20, 512)  2048        conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)      (None, 10, 20, 512)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 10, 20, 1024) 4719616     leaky_re_lu_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 10, 20, 1024) 4096        conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)      (None, 10, 20, 1024) 0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 10, 20, 1024) 0           add_21[0][0]                     \n",
      "                                                                 leaky_re_lu_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 10, 20, 512)  524800      add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 10, 20, 512)  2048        conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)      (None, 10, 20, 512)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 10, 20, 1024) 4719616     leaky_re_lu_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 10, 20, 1024) 4096        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)      (None, 10, 20, 1024) 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 10, 20, 1024) 0           add_22[0][0]                     \n",
      "                                                                 leaky_re_lu_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1024)         0           add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1025        global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 40,639,521\n",
      "Trainable params: 40,603,809\n",
      "Non-trainable params: 35,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the pipeline, I incorporated two callbacks - saving the best weights and early stopping callbacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_pipeline(data, model, learning_rate, filepath, bs, epoch):\n",
    "    save_best = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, \n",
    "                    save_weights_only=False, mode='min', period=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.005, patience=2, verbose=0, \n",
    "                                   mode='min', baseline=None, restore_best_weights=False)\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam(lr=learning_rate))\n",
    "    step_train = len(X_train)//bs+1\n",
    "    step_valid = len(X_valid)//bs+1\n",
    "    \n",
    "    #https://keras.io/models/sequential/\n",
    "    model.fit_generator(generate_batch(X_train, y_train, bs), steps_per_epoch=step_train, epochs=epoch, verbose=1, callbacks=[save_best, early_stopping], \n",
    "                        validation_data=generate_batch(X_valid, y_valid, bs), validation_steps=step_valid, \n",
    "                        class_weight=None, max_queue_size=10, workers=0, use_multiprocessing=False, shuffle=True, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need to define certain hyperparameters here, Learning rate, the number of Epoch and Batch size. \n",
    "\n",
    "With a number of experiment, I found that Learning rate of 0.01 for a start is OK and Batch size of 8 is maximum I can pass on with my local environment. In addition, 2 Epochs are sufficient with Learning rate of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Honey\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/1\n",
      "10113/10113 [==============================] - 5670s 561ms/step - loss: 6.0462 - val_loss: 0.5670\n"
     ]
    }
   ],
   "source": [
    "training_pipeline(data, model, lr, os.path.join(data_path, 'model_01.h5'), bs, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Honey\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Honey\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Honey\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:245: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Honey\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Honey\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Honey\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Honey\\.conda\\envs\\tf-gpu\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = load_model(os.path.join(data_path, 'model_01.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10107/10107 [==============================] - 6213s 615ms/step - loss: 0.0555 - val_loss: 0.0484\n"
     ]
    }
   ],
   "source": [
    "training_pipeline(data, model, lr, os.path.join(data_path, 'model_02.h5'), bs, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(os.path.join(data_path, 'model_02.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00001\n",
    "epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "6262/6262 [==============================] - 3235s 517ms/step - loss: 0.0272 - val_loss: 0.0456\n"
     ]
    }
   ],
   "source": [
    "training_pipeline(data, model, lr, os.path.join(data_path, 'model_03.h5'), bs, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
